DevOps Training :

Duration : 30th Sep. 2023 to 29th Oct.2023
10 Days - 40 Hours
40hours of DevOps Crash Course ::

Start Date: 30th Sep. 2023

9:30AM - 1:30PM IST (SAT&SUN)

*************************
Day - 1 - 30th Sep. 2023
*************************

			Introduction to DevOps!!!
			
				GIT,Jenkins,Build_Tools,Docker,Kubernetes,Ansible,Terraform,Prometheus&Grafana
				
				Scripting Languages : shell scripting, groovy scripting, yaml scripting --> python scripting
				
			Introduction to DevOps...!!!
			
			What is DevOps ?
			
			Software ?
			
				Application Software ::
				
				System Software ::
			
				Application - collection of programs
			
			Types of Software ?
			
				Destops Application Software 
				Web Application 
				Mobile Application
			
			Online _ Applications ::
				E_Commerce Application protals 
					www.amazon.com
					
			I want to create a E_Learning Portal ::: 
			
			SDLC - Software Development Life Cycle 
			
				Require Analysis 
				Design
				Coding/Development
				Testing
				Implementation/Production Release 
				Maintainence/Monitor
				
				Water-fall Model ::: 	Using this water fall model we can achieve this:
										It is linear in fashion
										We can go back and revise the plan/design.
										Water-fall Model cannot accommodate the new changes in mid of the project.
										If any new changes comes in, it should be considered as a new project.
						
				Require Analysis 
				Design
				Coding/Development
				Testing
				Implementation/Production Release 
				Maintainence/Monitor

					To create a E_Learning Portal ::: 	
					
					Core_Project 
						Require Analysis 				6 - 9 months to complete the product.
						Design
						Coding/Development
						Testing
						Implementation/Production Release 
						Maintainence/Monitor			
					
					Core_Project_v1 
						Require Analysis 				1-2 months to complete the product_v1.
						Design
						Coding/Development
						Testing
						Implementation/Production Release 
						Maintainence/Monitor	

			
				AGILE Methodologies :::

					Split the whole application into various Modules/Iterations :
					
						User_Registration
						User_login 
						User_Search_Courses
						User_Register_Course 
						User_Payment
						User_Track
				
					Iteration 1 : User_Registration
					
						Require Analysis 
						Design
						Coding/Development
						Testing
						Implementation/Production Release 
						Maintainence/Monitor				
				
				
					Iteration 2 : User_Login
					
						Require Analysis 
						Design
						Coding/Development
						Testing
						Implementation/Production Release 
						Maintainence/Monitor					
			
			
					Iteration 3 : New_CR
					
						Require Analysis 
						Design
						Coding/Development
						Testing
						Implementation/Production Release 
						Maintainence/Monitor	

				Using AGILE we can achieve ::
				
					Continuous Development
					Continuous Integration
					Continuous Testing
					Continuous Delivery 
					
				Using AGILE, we can achieve Continuous Delivery. But, NOT Continuous Deployment.
				
					Continuous Delivery 	--> Need Manual approval for any production release.
					
					Continuous Deployment 	--> This doesnt required any manual approval to production release.
					
					
				DevOps :::
				
					Is a Software Development Strategy, which helps to promote the collaboration between the teams like Development Teams and Operations Teams to achieve Continuous Development, Continuous Integration, Continuous Testing, Continuous Delivery, Continuous Deployment and Continuous Monitoring in an automated fashion.
					
				
					Based upon the Application Architecture:
					
						Monolith Application Architecture :::
							It is a tightly couple Application Architecture.
							
							Eg.:
								Billing System ::
								
									Create User Interface 
									Application Logic to validate the user inputs 
									Application Logic to Compute the inputs 
									Application Logic to save the trasaction to a dbase 
									Application Logic to generate the report
									
								
						Micro-Service based Application Architecture :::
							It is loosely coupled Application Architecture.
							Here the deployment is not at the application level
							It is at the service level.
							This allows to the independent development, testing and deployment of application to production.
							
							The whole application into various Modules/Iterations/micro-service :
							
							Eg.: 
								www.amazon.com :::
								
									Sign-Up			Micro-Service1 - Developer1 - Independently code, test, and deploy to production
									Sign_In
									Search 
									Add_to_Cart
									Payment
									Place_Order 
									Tracking
									
							3-tier Application Architecture
										Front_End 
										Application_logic 
										Back_End(Dbase)
										
										
						Application :: 
						
							Cloud 
							On-Premises
							Hybrid Environment ( Cloud & On-Premises)
							
				DevOps :::
				
					Is a Software Development Strategy, which helps to promote the collaboration between the teams like Development Teams and Operations Teams to achieve Continuous Development, Continuous Integration, Continuous Testing, Continuous Delivery, Continuous Deployment and Continuous Monitoring in an automated fashion.
					
				Teams ::::
		
				
					DevOps_Team :
					
						Infra-Structure Management Team
						Application Development Team 			==> java_application.
						Testing Team 							==> java_application.
						Release Management Team 
						Production Support Team
						Production Monitoring Team
						Security Team
				
				DevOps Stages ::::
				
					Continuous Development :
					
						Developer ::: Roles & Responsibilities :: Java Web Application Development 
						
						Tradional Approach:
							Code the Application
							Build - Compile the source code & Create artifacts (Binaries - *.war)
							Unit Test 
							Promote the code to higher environment - QA Testing
							Notify the Testing to pick up the application for further testing 
							
						DevOps Approach:
							Developers create the code & publish the latest src_code to GIT
							
							Using DevOps Automation:	
								Build - Compile the source code & Create artifacts (Binaries - *.war)
								Unit Test 
								Promote the code to higher environment - QA Testing
								Notify the Testing to pick up the application for further testing 
								
						Tools :
							IDEs - Eclipse based IDEs / Visual Studio Code / Visual Studio / Pycharm
							GIT 
							Jenkins 
						
					Continuous Integration :
							It is a capability of the team to continuously integrate the code for further testing without relying on other.

						
							Sign-Up			Micro-Service1 - Developer1 - Independently code, test, and deploy to production
							Sign_In
							Search 
							Add_to_Cart
							Payment
							Place_Order 
							Tracking
					
						Tools :
						
							Jenkins,Ansible,Docker,Kubernetes
					
					Continuous Testing 
							Implement continuous testing 
							
						Tools : 
							Jenkins,TestNG,Junit,Selenium
							
						
					Continuous Delivery / Continuous Deployment :
					
						Continuous Delivery and Continuous Deployment are used for production release.
								Continuous Delivery 	--> Need Manual approval for any production release.
								
								Continuous Deployment 	--> This doesnt required any manual approval to production release.						
						
						Tools :						
							Jenkins,Ansible,Docker,Kubernetes						
					
					Continuous Monitoring ::::
					
						Monitoring :::
						
							www.amazon.com	
							
							Infra-Structure Monitoring :::
									
										Network
										
										Traffic 
										
										CPU Utilization 
										
										Memory Utilization 
										
									80% 
						Tools : Prometheus&Grafana,Splunk, Datadog, Dynatrace, Nagios
						Jenkins									
							
							Application Monitoring :: AppDynamics
							
				

				
				Tools ::::
					
					- Open Source Tools 
							GIT,Jenkins,Build_Tools,Docker,Kubernetes,Ansible,Terraform,Prometheus&Grafana
							
					- Managed Services
					
						AWS 		DevOps Tools -> AWS Code commit, pipeline, build
						Azure 
						GCP
							
							
				Infra-Structure Team ::
				
					Provision the Infra-Structure & Configure the Servers 
					IAC Tools :
						Terraform 	- Server Provisioning 
						Ansible 	- Configuration Management
					
				
				DevOps Workflow / LifeCycle :::
				
				CI/CD Pipeline / Lifecycle :::
				
					Continuous Deployment can be achieved only using the matured level of DevOps :::
				
				Production Deployment Window ::: --> For (4 to 6 Hrs.)
				
				Appln_v1.5
				Appln_v1.6			==> New Version 
				
					Banking/Financial
					
					On_line Banking Service / Credit Transaction...........
					
						Production Testing ==> 
					
							- Try to fix that issue.
							- Rollback/Revert

					Continuous Delivery Process of Production Release.
					
					
					E_Commerce - amazon
					facebook
					google
					netflix 
					
					
					Continuous Deployment 
					
					DevOps Strategy / Process
				DevOps :::
				
					Is a Software Development Strategy, which helps to promote the collaboration between the teams like Development Teams and Operations Teams to achieve Continuous Development, Continuous Integration, Continuous Testing, Continuous Delivery, Continuous Deployment and Continuous Monitoring in an automated fashion.

					
						DevOps is all about ::
						
								People
								Process 
								Tools 

						
				DevOps Team :::

					DevOps Consultant/Architect/Lead 
					
					DevOps Associate / Sr. Associate
					DevOps Engineer / Sr. Engineer 
					DevOps Lead / Sr. Lead
					
				Water-fall / Agile / DevOps / DevSecOps / SRE / GITOps / AIOps/ MLOps
				
				
			
			Next working with DevOps Tools :
			
				GIT,Jenkins,Build_Tools,Docker,Kubernetes,Ansible,Terraform,Prometheus&Grafana
				
				GIT :::::
				
				
			Lab Environment ::::
			
				1. Create GITHUB Account - https://github.com/

				2. AWS Cloud Platform 
					Create AWS Free-Tier Account
							https://aws.amazon.com/console/
							
						- Valid Email_ID 
						- Valid Mobile Number 
						- Valid Credit Card/Debit Card - enabled for International Transaction 
							
					Create Virtual Machines/EC2 Instances
					
				3. Install SSH Client in local Machine.
					All Windows user can download and install MobaXterm - SSH Client 
							https://mobaxterm.mobatek.net/download.html
				
				4. Visual Studio Code - IDEs 
							https://code.visualstudio.com/download
				
				5. Create Account in DockerHub.
							https://hub.docker.com/
				
				
					
		Github ==> Is a remote repository ==> files and folders. 
				
				
*************************
Day - 2 - 1st Oct. 2023
*************************				
				
		Version Control System using GIT :::::
			
		Developer --> Java Web Application ::::
		
			Project_folder 
				src/main/java 					signin.java/index.jsp
				src/main/test 
				application.properties
				targets
			
			index.html ::
			
			<html>
			-~~~
			~~--
			--~~~-
			---
			---```
			``
			`````
			```
			---~~~~
			```
			```
			```
			</html>
			
			Version Control System :::
			
				Is used to version control the changes 
				Is used to track the Changes.
				
			index.html_v1.0	
			index.html_v1.1
			index.html_v1.2
			index.html_v1.3
			index.html_v1.4
			
			Types of VCS :::
			
				- Local Version Control System
				
				- Centralized Version Control System 
				
				- Distributed Version Control System 
				
			
			GIT :
				It is a open source Distributed Version Control System.
				It is used to Version Control the changes 
				It is used to Track the Changes 
				It is used to perform parallel Development.
				
			
				
			GITHUB 			==> Remote git repository 
			Azure Repos
			AWS Code Commit 
			Bitbucket 
			GitLab
						
			GIT Cli in the Local Machine.
						
			Local Machine 									=====>							Remote Server 
			
			Git file workflow :::
			

		
			Project_folder 
				src/main/java 					signin.java/index.jsp
				src/main/test 
				application.properties
				targets			
			
			Local Machine :::
			GIT Cli in the Local Machine.	
			
			Local Machine 												=====>						Remote Server 
			Working_Directory	--->		Index/Staging_Area	---> 	Local_Repository	--->      Remote Repository			
			index.jsp			git add 		index.jsp	git commit 	index.jsp_v1.0		git push 	index.jsp_v1.0
					
Git file workflow :::

Developer's Workload ::

New Project 
Enhancement/bugfix 

		git clone 	==>		It is used to copy/clone the entire remote repository to local machine.
		
		git add		==>		It is used to add the changes from working directory to staging area.
		
		git commit 	==>		It is used to commit the changes from staging area to local repository.
		
		git push	==>		It is used to push the changes from local repository to remote repository.
		
		
		git fetch/pull
					==>		Both git fetch and git pull are used to handle the incremental changes form remote repository.
							
							git fetch ==> It is just to check for the incremental changes in remote repository, if there is any incremental changes available in remote repository, it will be fetched in to the local repository. NOT into the work directory.
							
							git pull ==> It is used check for the incremental changes in remote repository, if there is any incremental changes available in remote repository, it will be update the changes in both local repository as well as in work directory.
							
		fork 		==> 	It is used to copy one remote repository to another remote repository.
		
		

			Install GIT Cli in Local Machine :::
				https://git-scm.com/downloads
				
				
			Maintain the Repository Structure ::::


				e:
				
				mkdir saOct23
				
				cd saOct23
				
				mkdir repo1
				
				cd repo1
				
				e:/saOct23/repo1				
				e:/saOct23/repo2
				e:/saOct23/repo3
				
			

		Developer's Workload ::

		New Project 
		Enhancement/bugfix 				
			
			
			
			git init	==> It is used to initialize empty git repository.
							It create .git directory and the default branch called 'master'
							
		
			git status	==> It is used to get the status of git repository.

			Local Machine 												=====>						Remote Server 
			Working_Directory	--->		Index/Staging_Area	---> 	Local_Repository	--->      Remote Repository			
				file1.txt
				
				
			For you level ::
			
			git init 
			
			Configure GIT for Author Name and Email ID.
			
			git config ::			# should be done before the very initial Commit.

				Global Configuration		# This is applicable for all the repositories in local Machine.
				
					git config --global user.name "Loksai"
					git config --global user.email "loksai@asdf.com"
					
				Local Configuration			# This is applicable within the a specific repository in local Machine.
				
					git config user.name "Loksai"
					git config user.email "loksai@asdf.com"	

			
			git add 
			
				git add <file_name>
				
				git add <file1_name> <file2_name>
				
				git add *.java
				
				git add .							# this will add all the files/changes to staging area. 
			
			git log
				
				git log
				git log --oneline
				git log --stat
				git log -3 
				git log --oneline -3 
				git log --stat -3 
				
			git show <commit>
			
			git diff				# Used to compare the changes between working dir & Local Repo.
			
			To remove the changes from staging area ::
			
				git rm --cached <file_name>			
								# This will remove the changes from staging area and take the changes back to working dir.
				
				git rm -f <file_name> 
								# This will permanently remove the changes from staging area and working dir.
				
			
			GIT IGNORE ::::
			
			
				Project_folder 
					src/main/java 					signin.java/index.jsp
					src/main/test 
					application.properties
					mysqldb_secrets
					test_credentials
					targets	
						*.war 
						*.war
					*.class
					pom.xml
					
					
				Git Ignore 	==> Is used to ignore the files from tracking.
				
				Create .gitignore file in repo. This should be the initial commit in the repo.
				
				*.war 
				*.class 
				sample1.txt
				sample.doc 
				targets/
				mysqldb_secrets
				test_credentials			
				
			
			git reset :::
			
				- It is used to undo the changes 
				- HEAD Pointer will be pointing to the specific commit point.
				- It will never create any new commit point.
				- git reset is not recommended in the shared repositories.
				
				
				git reset --soft <commit_id>
				
						==> It remove the changes from local repo.
							The changes will be back to staging area.
							The changes will be available in working dir. as well.
							HEAD Pointer will be pointing to the specific commit point.
				
				git reset --mixed <commit_id>			*** Is the default option.

						==> It remove the changes from local repo.
							The changes will NOT be taken back to staging area.
							But, the changes will be available in working dir.
							HEAD Pointer will be pointing to the specific commit point.
				
				git reset --hard <commit_id>

						==> It remove the changes from local repo.
							The changes will NOT be taken back to staging area.
							The changes will be permanently removed from working dir.
							HEAD Pointer will be pointing to the specific commit point.
			
			
			
			git revert :::	

				- It is used to undo the specific commit point. 
				- It will create a new commit point for tracking the changes.
				- git reset is recommended in the shared repositories.
				- git revert is similar to git reset. only difference is, revert will create a new commit point for tracking.
				
			
				git revert <specific commit_id>
				
			
			commit --> -m "CR2310 - Updated payment module"
			
		GIT Branching ::::
				- Git enable parallel Development ::::
				
				
			Repository :
					index.html 
					
			Repository :::

				master 		==> cm1,cm2,cm3 			# considered as production version of source code.
				
					feature1 ==> cm1,cm2,cm3
					


		GIT Branching Strategies ::::
							
Scenario1 :::

				master 		==> cm1,cm2,cm3 			# considered as production version of source code.				
					feature1 ==> cm1,cm2,cm3

Scenario2 :::

				master 		==> cm1,cm2,cm3 			# considered as production version of source code.

					Developer1_Branch ==> cm1,cm2,cm3
						feature1 ==> cm1,cm2,cm3
						feature2 ==> cm1,cm2,cm3
						
Scenario3 :::

				master 		==> cm1,cm2,cm3 			# considered as production version of source code.

					Integration_Branch ==> cm1,cm2,cm3,Dev1-features,Dev2-features
						Developer1_Branch ==> cm1,cm2,cm3,feature1,feature2
							feature1 ==> cm1,cm2,cm3
							feature2 ==> cm1,cm2,cm3
							
						Developer2_Branch ==> cm1,cm2,cm3,feature1,feature2
							feature1 ==> cm1,cm2,cm3
							feature2 ==> cm1,cm2,cm3
							
						
Scenario4 :::

				master 		==> cm1,cm2,cm3,cm4 			# considered as production version of source code.

					Release_Branch ==> cm1,cm2,cm3,Team1_Changes,Team2_Changes 
						Integration_Branch ==> cm1,cm2,cm3,Dev1-features,Dev2-features			Team1
							Developer1_Branch ==> cm1,cm2,cm3,feature1,feature2
								feature1 ==> cm1,cm2,cm3
								feature2 ==> cm1,cm2,cm3
								
							Developer2_Branch ==> cm1,cm2,cm3,feature1,feature2
								feature1 ==> cm1,cm2,cm3
								feature2 ==> cm1,cm2,cm3
								
						Integration_Branch ==> cm1,cm2,cm3,Dev1-features,Dev2-features			Team2
							Developer1_Branch ==> cm1,cm2,cm3,feature1,feature2
								feature1 ==> cm1,cm2,cm3
								feature2 ==> cm1,cm2,cm3
								
							Developer2_Branch ==> cm1,cm2,cm3,feature1,feature2
								feature1 ==> cm1,cm2,cm3
								feature2 ==> cm1,cm2,cm3
								
								
  502  cd e:
  503  mkdir SA-DevOps-Oct23
  504  cd SA-DevOps-Oct23/
  505  pwd
  506  mkdir samplerepo1
  507  clear
  508  ls
  509  cd samplerepo1/
  510  clear
  511  ls
  512  pwd
  513  git init
  514  clear
  515  ls
  516  ls -a
  517  ls
  518  ls -a
  519  cd .git/
  520  ls
  521  cd ..
  522  pwd
  523  clea
  524  clear
  525  cd ..
  526  ls
  527  mkdir samplerepo2
  528  cd samplerepo2/
  529  git init
  530  ls -a
  531  clear
  532  ls
  533  git status
  534  ls
  535  echo "Hello"
  536  echo "Hello" >> file1.txt
  537  ls
  538  cat file1.txt
  539  git status
  540  git add file1.txt
  541  git status
  542  git commit -m "Created file1.txt"
  543  git status
  544  git log
  545  clear
  546  ls
  547  git status
  548  echo "rec1" >> file2.txt
  549  git status
  550  git add file2.txt
  551  git status
  552  git commit -m "Created file2.txt"
  553  git log
  554  clear
  555  ls
  556  git log
  557  git config user.name "Loksai"
  558  echo "rec1" >> file3.txt
  559  git add file3.txt
  560  git commit -m "created file3.txt"
  561  git log
  562  cd ..
  563  ls
  564  mkdir samplerepo3
  565  cd samplerepo3/
  566  git init
  567  echo "rec1" >> f1.txt
  568  git add f1.txt
  569  git commit -m "Created f1.txt"
  570  git log
  571  git config --global user.name "Loksai"
  572  echo "rec1" >> f2.txt
  573  git add f2.txt
  574  git commit -m "Created f2.txt"
  575  git log
  576  clear
  577  cd ..
  578  cd samplerepo1/
  579  ls
  580  git status
  581  clear
  582  git log
  583  clear
  584  echo "Rec1" >> f1.txt
  585  git add f1.txt
  586  git commit -m "Created f1.txt"
  587  ls
  588  git status
  589  echo "rec1" >> s1.txt
  590  git status
  591  echo "rec1" >> s2.txt
  592  echo "rec1" >> s3.txt
  593  echo "rec1" >> q1.java
  594  echo "rec1" >> q2.java
  595  echo "rec1" >> l1.html
  596  echo "rec1" >> l2.html
  597  echo "rec1" >> readme.md
  598  echo "rec1" >> readme.doc
  599  git status
  600  git add l1.html l2.html
  601  git status
  602  git add *.java
  603  git status
  604  git add .
  605  git status
  606  git log
  607  git commit -m "Create Project files"
  608  git log
  609  echo "rec1" >> w1.txt
  610  git add .
  611  git commit -m "created w1.txt"
  612  echo "rec1" >> w2.txt
  613  git add .
  614  git commit -m "created w2.txt"
  615  echo "rec1" >> w3.txt
  616  git add .
  617  git commit -m "created w3.txt"
  618  clear
  619  git log
  620  git log --oneline
  621  git log --stat
  622  git log -3
  623  git log -2
  624  git log -1
  625  git log --oneline -3
  626  git log --stat -2
  627  clear
  628  git log --oneline
  629  git show ed1c8e6
  630  git show 14d498b
  631  git log --stat -1
  632  clear
  633  ls
  634  cat readme.
  635  cat readme.md
  636  echo "rec2" >> readme.md
  637  echo "rec3" >> readme.md
  638  git diff
  639  git log -4
  640  git log --oneline
  641  clear
  642  git status
  643  git add .
  644  git commit -m "updated readme.md"
  645  clear
  646  git status
  647  cd ..
  648  mkdir samplerepo4
  649  cd samplerepo4/
  650  git init
  651  clear
  652  echo "rec1" >> f1.txt
  653  git add .
  654  git commit -m "Created f1.txt"
  655  git status
  656  clear
  657  ls
  658  echo "rec1" >> f2.txt
  659  git status
  660  git add f2.txt
  661  git status
  662  clear
  663  git status
  664  ls
  665  git rm --cached f2.txt
  666  git status
  667  git add .
  668  git statu
  669  git status
  670  git rm -f f2.txt
  671  git status
  672  ls
  673  clear
  674  git status
  675  echo "rec1" >> q1.txt
  676  git add .
  677  git commit -m "created q1.txt"
  678  echo "rec1" >> q2.txt
  679  git add .
  680  git commit -m "created q3.txt"
  681  echo "rec1" >> q3.txt
  682  git add .
  683  git commit -m "created q3.txt"
  684  clear
  685  ls
  686  git status
  687  echo "rec1" >> w1.txt
  688  git add .
  689  echo "rec1" >> w2.txt
  690  git add .
  691  clear
  692  git status
  693  git commit -m "adfasd"
  694  clear
  695  cd ..
  696  clear
  697  ls
  698  mkdir samplerepo5
  699  cd samplerepo5
  700  clear
  701  ls
  702  git init
  703  vi .gitignore
  704  git add .
  705  git commit -m "Initial Commit for .gitignore file"
  706  cat .gitignore
  707  clear
  708  git status
  709  clear
  710  cat .gitignore
  711  ls
  712  ls -a
  713  echo "rec1" >> sample.txt
  714  git status
  715  echo "rec1" >> q1.class
  716  git status
  717  ls
  718  echo "rec1" >> sample1.txt
  719  git status
  720  git add .
  721  git commit -m "created sample.txt"
  722  git status
  723  git log
  724  clear
  725  ls
  726  git log
  727  cd ..
  728  clear
  729  mkdir samplerepo6
  730  cd samplerepo6/
  731  clear
  732  git init
  733  echo "rec1" >> f1.txt
  734  git add .
  735  git commit -m "CM1"
  736  echo "rec1" >> f2.txt
  737  git add .
  738  git commit -m "CM2"
  739  echo "rec1" >> f3.txt
  740  git add .
  741  git commit -m "CM3"
  742  echo "rec1" >> f4.txt
  743  git add .
  744  git commit -m "CM4"
  745  echo "rec1" >> f5.txt
  746  git add .
  747  git commit -m "CM5"
  748  clear
  749  git log --oneline
  750  ls
  751  git status
  752  git ls-files
  753  git reset --soft b422882
  754  git status
  755  ls
  756  git ls-files
  757  git log --oneline
  758  git commit -m "CM5.1"
  759  git status
  760  ls
  761  git ls-files
  762  git log --oneline
  763  git reset --mixed b422882
  764  git status
  765  ls
  766  git ls-files
  767  git log --oneline
  768  git add .
  769  git commit -m "CM5.2"
  770  git log --oneline
  771  git status
  772  ls
  773  git ls-files
  774  git reset --hard b422882
  775  git status
  776  git ls-files
  777  ls
  778  git log --oneline
  779  git reset --hard b7e46c7
  780  ls
  781  git log --oneline
  782  git ls-files
  783  clear
  784  ls
  785  echo "rec1" >> w1.txt
  786  git add .
  787  git commit -m "CM2"
  788  echo "rec1" >> w2.txt
  789  git add .
  790  git commit -m "CM3"
  791  echo "rec1" >> w3.txt
  792  git add .
  793  git commit -m "CM3"
  794  clear
  795  git log --oneline
  796  git show 5f02ab2
  797  git revert 5f02ab2
  798  git status
  799  git log --oneline
  800  ls
  801  git revert 1ef3b24
  802  git log --oneline
  803  ls
  804  clear
  805  git status
  806  echo "rec1" >> l1.txt
  807  git add .
  808  git commit -m "asdfasdfasdfasasdfdfs"
  809  git log --oneline
  810  git commit -M "CR1023 - created l1.txt"
  811  git commit -m "CR1023 - created l1.txt"
  812  git log --oneline
  813  git commit --amend -m "CR1023 - created l1.txt"
  814  git log --oneline
  815  cd ..
  816  pwd
  817  history


*************************
Day - 3 - 7th Oct. 2023
*************************	

		Git Branching :::
		
				master 		==> cm1,cm2,cm3 			# considered as production version of source code.	
				
					feature1 ==> cm1,cm2,cm3
					feature2 ==> cm1,cm2,cm3
					feature3 ==> cm1,cm2,cm3
					


		Create branch :::
		
			git switch -c <branch_name>
			
			git branch <branch_name>
			
			git checkout -b <branch_name>
			
		Make some incremental changes in current branch & Merge the changes to target branch.
		
		To merge the changes to target branch ::
		
			- Switch to Target branch 
			- Merge the changes to target branch using current branch name.
			
			git switch master 
			
			git merge feature1
			
			
		How to handle the shared file & handle merge conflicts :::
		
			Merge Conflict :::
			
			
			master :
				
					file1.txt
					
						rec1 
						afasdfasdfsdfsdafsdfrec2
					
					
				feature1 
				
					file1.txt 					
						rec1 
						afasdfasdfsdfsdafsdfrec2
						
				feature2 
				
					file1.txt 					
						rec1 
						rec2asdfasdfasdfasdfasdfasdf
						
			How to fix Merge Conflict :::
			
				1. Identify the file(s) causing merge conflict.
				2. Review the changes happened in the file(s).
				3. Decide who's changes has to be retained in the target branch.
				4. Make necessary changes, remove all the header and footers created during merge conflict.
				5. Add and Commit the changes in target branch.
				
			Prevent Merge Conflict :::
			
				With proper Review of the changes.
				
			git rebase & squash 
			
			Git Rebase :::
			
				It is used to keep the current branch in sync with target branch.
				It is used to prevent Merge Conflicts in target branch.
				It is also used to maintain the linear commit history.
				
				*** As a best practise always perform rebase before any merge action.
				
				master :: cm1,cm2,cm3
				
					feature1 :: cm1,cm2,cm3
					
					feature2 :: cm1,cm2,cm3
					
					
				master :: cm1,cm2,cm3
				
									cm1,cm2,cm3,f1cm1,f1cm2			# Upon merging feature1
									
									cm1,cm2,cm3,f1cm1,f1cm2,f2cm1,f2cm2,f2cm3  # Upon merging feature2 								
									
				
					feature1 :: cm1,cm2,cm3,f1cm1,f1cm2
					
						git rebase master 				# Should be executed from the current branch.
					
						git switch master 
						
						git merge feature1
					
					feature2 :: cm1,cm2,cm3,f2cm1,f2cm2,f2cm3					
					
						git rebase master 				# Should be executed from the current branch.
						
							cm1,cm2,cm3,f1cm1,f1cm2,f2cm1,f2cm2,f2cm3
							
						git switch master 
						
						git merge feature2
					
			

			GIT Squash ::::
			
				It is merge option used to combine the commits before merging.
				
			
				master :: cm1,cm2,cm3
				
								cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,10,...................,n  # Upon merging feature1
				
					feature1 :: cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,10,...................,n
								
					git switch master 
					
					git merge feature1 
					


Scenario3 :::

				master 		==> cm1,cm2,cm3 			# considered as production version of source code.
								cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n

					Integration_Branch ==> cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n
					
					cm1,cm2,cm3,Developer2_features,Developer1_features
						Developer1_Branch ==> cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n
							feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n
							feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5,6,7,8,9,....,n
							
						Developer2_Branch ==> cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n,f2cm1,2,3,4,5,6,7,8,9,....,n
							feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5,6,7,8,9,....,n
							feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5,6,7,8,9,....,n
							
							


Scenario4 :::

				master 		==> cm1,cm2,cm3,REL1023 			# considered as production version of source code.

					Release_Branch ==> cm1,cm2,cm3,Team1_Changes,Team2_Changes 
					
						Integration_Branch ==> cm1,cm2,cm3,Dev1-features,Dev2-features			Team1
							Developer1_Branch ==> cm1,cm2,cm3,D1feature1,D2feature2
								feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5
								feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5
								
							Developer2_Branch ==> cm1,cm2,cm3,D2feature1,D2feature2
								feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5
								feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5
								
						Integration_Branch ==> cm1,cm2,cm3,Dev1-features,Dev2-features			Team2
							Developer1_Branch ==> cm1,cm2,cm3,D1feature1,D1feature2
								feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5
								feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5
								
							Developer2_Branch ==> cm1,cm2,cm3,D2feature1,D2feature2
								feature1 ==> cm1,cm2,cm3,f1cm1,2,3,4,5
								feature2 ==> cm1,cm2,cm3,f2cm1,2,3,4,5
								
				
				Cherry-pick 
				
				
				git cherry-pick <commit_id>
				
				git cherry-pick Team1_Changes
				
		
			How to access the remote repository :::
			
			github 
			gitlab
			bitbucket 
			az Repos
			AWS CodeCommit
			
			Developers' Workload :::
			
				Enhancement/bugfix			https://github.com/SA-RDevOps2/Training_Documents
						The Source code must be already present in remote repositories
				



					git clone 	==>		It is used to copy/clone the entire remote repository to local machine.
					
					git add		==>		It is used to add the changes from working directory to staging area.
					
					git commit 	==>		It is used to commit the changes from staging area to local repository.
					
					git push	==>		It is used to push the changes from local repository to remote repository.
					
					
					git fetch/pull
								==>		Both git fetch and git pull are used to handle the incremental changes form remote repository.
										
										git fetch ==> It is just to check for the incremental changes in remote repository, if there is any incremental changes available in remote repository, it will be fetched in to the local repository. NOT into the work directory.
										
										git pull ==> It is used check for the incremental changes in remote repository, if there is any incremental changes available in remote repository, it will be update the changes in both local repository as well as in work directory.
										
										git pull => git fetch + git merge 
										
					fork 		==> 	It is used to copy one remote repository to another remote repository.
					
					
					
					
					
					git clone https://github.com/SA-RDevOps2/testrepo1.git
					
					make local changes in a new feature branch 
					
					git add 
					
					git commit 
					
					git push -u origin <branch_name>
					
					fetch / pull :::
		
		
		
				New Project ::
				
						The Source code will not be there in remote repositories
						It is create and test in local machine and then published to remote repository.
						
						
				git init 
				
				git add 
				
				git commit 
				
				git remote -v 			# Used to get the list of remote repositories attached to local repository.
				
				git remote add origin <remote_repo_url>
				
				git remote remove origin
				
				
		GIT STASH ::::
		
				It is used to save the uncommitted changes to a temporary area / branch.
				It will move the changes from staging Area to temporary area.
				
				master :::
				
					cm1,2,3,4,5,6,7,.....
					
			
				Appln_repo 
				
					master : cm1,cm2,c3 
					
						feature1 : cm1,cm2,cm3
						
							making code changes 
							 git add .
							
					git stash save "created f1.txt"

					git stash list 
					
					git stash apply		==> Just to apply the changes back to staging area. But the changes remain in stash list.
					git stash pop 		==> Apply the changes back to staging area as well as remove that entry from stash list.
					
					git stash drop / stash@{1} 		==> Drop the latest entry from stash list.
					git stash clear 	==> Clear all the enries from stash list.
							
							
  501  cd e:
  502  ls
  503  cd SA-DevOps-Oct23/
  504  clear
  505  ls
  506  mkdir testrepo1
  507  cd testrepo1/
  508  clear
  509  git init
  510  git status
  511  ls
  512  clear
  513  echo "rec1" >> s1.txt
  514  git add .
  515  git commit -m "cm1"
  516  echo "rec1" >> s2.txt
  517  git add .
  518  git commit -m "cm2"
  519  echo "rec1" >> s3.txt
  520  git add .
  521  git commit -m "cm3"
  522  clear
  523  ls
  524  git log --oneline
  525  git branch
  526  git switch -c feature1
  527  ls
  528  git log --oneline
  529  git branch
  530  git switch master
  531  git branch
  532  git checkout -b feature2
  533  git switch master
  534  git branch feature3
  535  git branch feature4
  536  git branch feature5
  537  git branch
  538  clear
  539  git log --oneline
  540  git switch feature1
  541  git log --oneline
  542  ls
  543  echo "rec1" >> q1.txt
  544  git add .
  545  git commit -m "CM1 from feature1"
  546  echo "rec1" >> q2.txt
  547  git add .
  548  git commit -m "CM2 from feature1"
  549  git log --oneline
  550  ls
  551  git switch master
  552  ls
  553  git log --oneline
  554  git merge feature1
  555  git log --oneline
  556  ls
  557  git switch feature2
  558  echo "rec1" >> w1.txt
  559  git add .
  560  git commit -m "cm1 from feature2"
  561  git log --oneline
  562  git switch master
  563  git merge feature2
  564  clear
  565  ls
  566  git  log --oneline
  567  cd ..
  568  mkdir testrepo2
  569  clear
  570  cd testrepo2/
  571  git init
  572  clear
  573  echo "rec1" >> q1.txt
  574  git add .
  575  git commit -m "cm1 from master"
  576  git branch feature1
  577  git branch feature2
  578  git log --oneline
  579  git switch feature1
  580  ls
  581  cat q1.txt
  582  echo "rec2 from feature2" >> q1.txt
  583  cat q1.txt
  584  vi q1.txt
  585  cat q1.txt
  586  git add .
  587  git commit -m "CM1 from feature1"
  588  git status
  589  git log --oneline
  590  git switch master
  591  git merge feature1
  592  cat q1.txt
  593  git switch feature2
  594  cat q1.txt
  595  echo "rec2 from feature2" >> q1.txt
  596  git add .
  597  git commit -m "CM1 from feature2"
  598  git log --oneline
  599  ls
  600  cat q1.txt
  601  git switch master
  602  git merge feature2
  603  git status
  604  vi q1.txt
  605  git add .
  606  git commit -m "Resolved MErge Conflict"
  607  git status
  608  git log --oneline
  609  cat q1.txt
  610  clear
  611  ls
  612  cd ..
  613  mkdir testrepo3
  614  cd testrepo3
  615  git init
  616  clear
  617  echo "rec1" >> a1.txt
  618  git add .
  619  git commit -m "cm1"
  620  echo "rec1" >> a2.txt
  621  git add .
  622  git commit -m "cm2"
  623  echo "rec1" >> a3.txt
  624  git add .
  625  git commit -m "cm3"
  626  clear
  627  ls
  628  git log --oneline
  629  git branch feature1
  630  git branch feature2
  631  git switch feature1
  632  git log --oneline
  633  echo "rec1" >> w1.txt
  634  git add .
  635  git commit -m "f1cm1"
  636  echo "rec1" >> w2.txt
  637  git add .
  638  git commit -m "f1cm2"
  639  git log --oneline
  640  git rebase master
  641  git switch master
  642  git merge feature1
  643  git switch feature2
  644  git log --oneline
  645  echo "rec1" >> e1.txt
  646  git add .
  647  git commit -m "f2cm1"
  648  echo "rec1" >> e2.txt
  649  git add .
  650  git commit -m "f2cm2"
  651  echo "rec1" >> e3.txt
  652  git add .
  653  git commit -m "f2cm3"
  654  git log --oneline
  655  git rebase master
  656  git log --oneline
  657  git rebase master
  658  ls
  659  git switch master
  660  ls
  661  git merge feature2
  662  ls
  663  git log --oneline
  664  clea
  665  cls
  666  clear
  667  ls
  668  git branch
  669  git log --oneline
  670  git switch feature4
  671  git switch -c feature4
  672  git log --oneline
  673  echo "rec1" > i1.txt
  674  git add .
  675  git commit -m "f4cm1"
  676  echo "rec1" >> i1.txt
  677  git add .
  678  git commit -m "f4cm2"
  679  echo "rec1" >> i1.txt
  680  git add .
  681  git commit -m "f4cm3"
  682  echo "rec1" >> i1.txt
  683  git add .
  684  git commit -m "f4cm4"
  685  echo "rec1" >> i1.txt
  686  git add .
  687  git commit -m "f4cm5"
  688  echo "rec1" >> i1.txt
  689  echo "rec1" >> i1.txt
  690  git add .
  691  git commit -m "f4cm6"
  692  git log --oneline
  693  cat i1.txt
  694  git switch master
  695  git merge --squash feature4
  696  git status
  697  git commit -m "Combined commits from feature4"
  698  git status
  699  git log --oneline
  700  ls
  701  cat i1.txt
  702  git show 30d79ba
  703  clear
  704  cd ..
  705  mkdir remoterepos
  706  cd remoterepos/
  707  clear
  708  git clone https://github.com/SA-RDevOps2/testrepo1.git
  709  ls
  710  cd testrepo1/
  711  ls
  712  git status
  713  git remote -v
  714  ls
  715  git branch
  716  git switch -c localfeature1
  717  git log --oneline
  718  git statu
  719  git status
  720  echo "rec1" >> localfile1.txt
  721  git add .
  722  git commit -m "localfile1 created"
  723  git status
  724  git log --oneline
  725  git push -u origin localfeature1
  726  echo "rec1" >> localfile2.txt
  727  git add .
  728  git commit -m "localfile2 created"
  729  git push -u origin localfeature1
  730  git push -u origin localfeature1
  731  clear
  732  git switch main
  733  git status
  734  ls
  735  git fetch
  736  ls
  737  git fetch
  738  git pull
  739  ls
  740  ls
  741  git pull
  742  ls
  743  clear
  744  cd ..
  745  mkdir temprepo1
  746  cd temprepo1/
  747  clear
  748  git init
  749  clear
  750  ls
  751  echo "rec1" >> file1.txt
  752  git add .
  753  git commit -m "CM1 from local master"
  754  git branch -M main
  755  git branch -M master
  756  git remote -c
  757  clear
  758  git remote -v
  759  git remote add origin https://github.com/SA-RDevOps2/testrepo2.git
  760  git remote -v
  761*
  762  git remote -v
  763  git remote remove origin
  764  git remote -v
  765  git remote add origin https://github.com/SA-RDevOps2/testrepo2.git
  766  git remote add origin1 https://github.com/SA-RDevOps2/testrepo1.git
  767  git remote -v
  768  git remote remove origin
  769  git remote remove origin1
  770  clea
  771  clear
  772  git branch
  773  git log --oneline
  774  git branch feature1
  775  git switch feature1
  776  echo "rec" >> f1.txt
  777  echo "rec" >> f1.txt
  778  echo "rec" >> f1.txt
  779  echo "rec" >> f1.txt
  780  git add .
  781  git add .
  782  git status
  783  git switch -c adhoc-brnch1
  784  git status
  785  ls
  786  git switch feature1
  787  git status
  788  git stash save "created f1.txt"
  789  git stash list
  790  git status
  791  echo "rec" >> f2.txt
  792  git add .
  793  git status
  794  git stash save "created f2.txt"
  795  git stash list
  796  git stash apply
  797  git stash list
  798  git stash drop
  799  git stash list
  800  git status
  801  git stash save "created f2.txt"
  802  git status
  803  git stash list
  804  git stash pop
  805  git stash list
  806  git status
  807  git commit -m "Created f2.txt"
  808  git stash clear
  809  git stash list
  810  git status
  811  echo "rec1" >> g1.txt
  812  git add
  813  git add .
  814  git stash save "created g1.txt"
  815  echo "rec1" >> g2.txt
  816  git add .
  817  git stash save "created g2.txt"
  818  echo "rec1" >> g3.txt
  819  git add .
  820  git stash
  821  git stash list
  822  git log --oneline
  823  git stash drop stash@{2}
  824  git stash list
  825  git stash apply stash@{1}
  826  git status
  827  git commit -m "asdfas"
  828  ls
  829  git stash list
  830  git stash clear
  831  history
					
GIT :::

		VCS 
		GIT 
		Git file work flow 
		reset / revert 
		git branching strategies 
		merge 
		merge conflicts 
		rebase/squash
		stash
		handling remote repositories.
		
							
#################################################################


*************************
Day - 3 - 7th Oct. 2023
*************************	


		Jenkins --> Build Orchestration Tool ::::
		
			Jenkins is a open source build Orchestration Tool :::
			
				Jenkins Architecture :::
					
					Jenkins_Master 		==> (VM) --> Used to Create/Manage Jenkins Jobs and Schedule the jobs to slave nodes.
						Jenkins_Slave1	==> (VM) --> Used to perform the actual builds. 
						Jenkins_Slave2	==> (VM) --> Used to perform the actual builds. 		
						Jenkins_Slave3	==> (VM) --> Used to perform the actual builds. 			
						Jenkins_Slave4	==> (VM) --> Used to perform the actual builds. 		
			
		
			Jenkins 
			bamboo
			Azure Pipelines 
			AWS Code Pipelines 
			Gitlab-ci
			
			Application Build ==> Is a process of compiling the source code and create the artifacts(*.war/*.jar)
			
			Jenkins ::
			
				Development Team / DevOps Team ::
				
				Development Team's Perspective ::
					Developers are just the consumers.
					
				DevOps Team's Perspective ::
					DevOps Team ==> Owner of Jenkins Servers 
									Adminstrate Jenkins Servers.
									
									
			Role of DevOps Team :::
			
				Installation and Configuration of Jenkins Server.
				Plugins Management 
				User Management
				Credential Management 
				Tools Management 
				Jenkins System Management 
				Jenkins Master & Slave Node Configuration Management 
				Jenkins CI/CD - Automated Jobs/Pipeline/Project Creation 
				Onboard Application Teams to Jenkins
				Managing Upgrades
				Backup and Recoveries
				

			
				AWS Cloud Platform :::	
					
				1. Create GITHUB Account - https://github.com/

				2. AWS Cloud Platform 
					Create AWS Free-Tier Account
							https://aws.amazon.com/console/
							
						- Valid Email_ID 
						- Valid Mobile Number 
						- Valid Credit Card/Debit Card - enabled for International Transaction 
							
					Create Virtual Machines/EC2 Instances
					
						AWS Regions ==> 
							AWS Availability Zones (Data Centers)
					
					
				3. Install SSH Client in local Machine.
					All Windows user can download and install MobaXterm - SSH Client 
							https://mobaxterm.mobatek.net/download.html
				
				4. Visual Studio Code - IDEs 
							https://code.visualstudio.com/download
				
				5. Create Account in DockerHub.
							https://hub.docker.com/				
			
			
			
							
			Installation and Configuration of Jenkins Server.		https://www.jenkins.io/doc/book/installing/
			
				Create Virtual Machines/EC2 Instances	
					Launch 2 VMs 
						Jenkins_Master 				
							Jenkins_Slave_node1		-- Build Server 
							
							
		
				

*************************
Day - 4 - 8th Oct. 2023
*************************		
				
			Installation and Configuration of Jenkins Server.		https://www.jenkins.io/doc/book/installing/
			
				Create Virtual Machines/EC2 Instances	
					Launch 2 VMs 
						Jenkins_Master 				
							Jenkins_Slave_node1		-- Build Server 
							
			
			Linux : 
			
				Distributions
				
						Install/Manage any Software package in Linux, we need Package Manager -
				
				Ubuntu					- apt-get 	
				
				centos/RHEL				- yum 
				Fedora(latest_version)	- dnf	
				
				
				1 VM --> 750 hr/month 
				
				10 VMs --> 75 hr/month
				
				
				Jenkins Service runs in port 8080
							
				Connect to VM ::
				
					Using - 
						EC2 Instance Connect 
						SSH Agents : MobaXterm : 
							Remote Public_IP of host, User_Name(ubuntu), *.pem
						Terminals/Command Prompt 
						
						
				Connect to VM :

sudo -i

# Install Jdk :

sudo apt update -y
sudo apt install openjdk-11-jre -y
java -version

# Install Jenkins :

curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins -y

jenkins --version

systemctl status jenkins
systemctl start jenkins
systemctl stop jenkins
systemctl restart jenkins
systemctl enable jenkins

Login to Jenkins_Master :
http://<public_IP_Addres>:8080/
Eg.: 
http://3.108.252.236:8080/





		Create Jenkins Project ::
		
			Free Style Projects  
			
			Pipeline Projects/Jobs 
			
				Scripts using Groovy scripting Language.
				
					Scripted Pipeline 
					
					Declarative Pipeline
					
					
			Create Jenkins Jobs 
			Build 
			Check the console output 
			Troubleshooting Jobs 
			
			Handling Variables in Jenkins ::
			
				Jenkins - Environment Variables 
				
				User Defined Variables
				
			
			Environments
			
			Non-Production																Production Environment
			
			DEV 
			QA 
			UAT 																			PROD Servers
			
		
			Pipeline Projects/Jobs 
			
				Scripts using Groovy scripting Language.
				
					Scripted Pipeline 
					
					Declarative Pipeline
					
			Jenkins CI/CD - Automated Jobs/Pipeline/Project Creation 
				Onboard Application Teams to Jenkins
			
			Master & Slave Nodes 
			
				Jenkins_Master 		==> Used to Create and Schedule the jobs/pipeline projects 
				
					Jenkins_Slave1	==> Used to perform the actual build.
					
				DevOps Approach:
					Developers create the code & publish the latest src_code to GIT			==> Java Web Application 
					
					Using DevOps Automation:	
						Build - Compile the source code & Create artifacts (Binaries - *.war)
						Unit Test 
						Promote the code to higher environment - QA Testing
						Notify the Testing to pick up the application for further testing 
						
						
			How to create Jenkins Slave Machines and config in Jenkins Master:
			
				Jenkins_Master 		==> VM - Used to Create and Schedule the jobs/pipeline projects
					Jenkins_Slave1	==> VM - Used to perform the actual build.	
									==> Tools :	git,jdk,maven https://maven.apache.org/install.html

							How the applications are build ? 
								Maven tool to build 
								Parameters 
								dependencies
							
							What are the Application Builds tool we can use?
							How to config the build tool in the slave node?
							
							
						install : MAVEN Build Tool 
						Dependencies for build 
						
						
						Maven Build Tool :::
							pom.xml 	
									==> This is used to define all the dependencies and plugins used to perform automated maven Application Build & Unit Testing.
									
							maven goals
									==> Used to control the build or testing activities.
									clean
									test
									package 
									build 
									install
									
							All these are part of Source Code Repository maintained by developers.
							
					
Jenkins_Slave Node Configuration ::::					

sudo -i
sudo apt update -y

# Install git :

apt install git -y
git --version 

# Install jdk :

sudo apt update -y
sudo apt install openjdk-11-jre -y
java -version

# Install Maven :

sudo apt update -y
sudo apt install maven -y
mvn --version 

				Jenkins_Master 		==> VM - Used to Create and Schedule the jobs/pipeline projects
					Jenkins_Slave1	==> VM - Used to perform the actual build.	
									==> Tools :	git,jdk,maven https://maven.apache.org/install.html
									
									

VM1 & VM2  ==> SSH Protocol 

	SSH Connection is based upon Key based Authentication.
	
	User ID.
	Host_name 
	Authentication ::
		Password 
		Key 
		Token 
		Passwordless Auth 
		
		
	Create Pipeline Projects :::
	
			Pipeline Projects/Jobs 
			
				Scripts using Groovy scripting Language.
				
					Scripted Pipeline 
					
					Declarative Pipeline
					
			Pipeline Projects :::
			
				Stages :::
					Tasks 
				
				Checkout_Src_Code
				Build 
				Create Artifacts 
		
		
		Maven Goal:
			build 	-- It is jus to buid the applications Compile 
			test    --> it will build and perform automated unit testing 
			clean   --> Used to clean the target library/dir.
			package --> Used to build, unit testing, create binaries in target folder


pipeline {
    
	agent { label 'slave1' }

    tools {
        maven "maven-3.6.3"
    }

    stages {
        stage('SCM_Checkout') {
            steps {
                echo 'Perform SCM Checkout'
				git 'https://github.com/LoksaiETA/Java-mvn-app2.git'
            }
        }
        stage('Maven_Build') {
            steps {
                echo 'Perform Maven Build'
				sh 'mvn clean package'
            }
        }
        stage('Deploy to QA_Server') {
            steps {
                echo 'Hello World'
            }
        }
    }
}

10AM - 2PM from 14th Oct. 20023



#*************************************************************************************************************
#Jenkins Master :::
#*************************************************************************************************************
sudo -i 

# Install Java :::

sudo apt update
sudo apt install openjdk-11-jre
java -version


# Install Jenkins :::


curl -fsSL https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key | sudo tee \
  /usr/share/keyrings/jenkins-keyring.asc > /dev/null
echo deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc] \
  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt-get update
sudo apt-get install jenkins

jenkins --version 


systemctl status jenkins
systemctl start jenkins
systemctl restart jenkins
systemctl stop jenkins
systemctl enable jenkins

	<public_ip_Address>:8080 

#*************************************************************************************************************
Configure Slave Node1 for Java Maven App. :
#*************************************************************************************************************


#Install GIT :

sudo apt install git -y
git --version

#Install Java ::

sudo apt update -y 
sudo apt install openjdk-11-jre -y
java -version


Install Maven - Build Tool :
https://maven.apache.org/install.html

sudo apt install maven -y 

mvn --version

Create User in Jenkins Slave Machine & Create SSH Keys 

	SSH Keys --> is composed of public and private keys 


#Add User : 

#useradd -m -d /home/devopsadmin devopsadmin
#useradd devopsadmin

useradd devopsadmin -s /bin/bash -m -d /home/devopsadmin

su - devopsadmin

#ssh-keygen

#for Ubuntu ::
ssh-keygen -t rsa -b 2048 -m PEM


ls ~/.ssh 

#You should see following two files:

#id_rsa - private key
#id_rsa.pub - public


cat id_rsa.pub > authorized_keys

chown -R devopsadmin /home/devopsadmin/.ssh
chmod 600 /home/devopsadmin/.ssh/authorized_keys
chmod 700 /home/devopsadmin/.ssh


In Jenkins Master - Add Node Configuration
		
		Goto Manage Jenkins - Add New Node Configuration

#**************************************************************************************************


*************************
Day - 5 - 14th Oct. 2023
*************************	


pipeline {
    
	agent { label 'slave1' }

    tools {
        maven "maven-3.6.3"
    }

    stages {
        stage('SCM_Checkout') {
            steps {
                echo 'Perform SCM Checkout'
				git 'https://github.com/LoksaiETA/Java-mvn-app2.git'
            }
        }
        stage('Maven_Build') {
            steps {
                echo 'Perform Maven Build'
				sh 'mvn clean package'
            }
        }
        stage('Deploy to QA_Server') {
            steps {
                script{
				sshPublisher(publishers: [sshPublisherDesc(configName: 'SA_DR_QA_Server', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: '', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '.', remoteDirectorySDF: false, removePrefix: 'target/', sourceFiles: 'target/mvn-hello-world.war')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])
				}
            }
        }
    }
}


	- Deployment 
	- Automate the Deployment 
	- Email_Notification
	
	1. Create QA Server - ubuntu & add port 8080
	2. Install the tools :
			jdk,tomcat
			
			
	Target Environment :
	
		QA 	web Application Server(Software) - Tomcat(8080)/Nginx(80)
			
		UAT 
		Prod 

	Deployment ::::
			--> It is just a process of copying the application artifacts from one server to another servers (Target servers)
			
			Source Path ::: 														Target_Path :::
			Slave_Node:																QA_Server:
			
				target/mvn-hello-world.war					=====>						/opt/tomcat/webapps



	Install Publish Over SSH Plugins in Jenkins and restart jenkins.


Build Triggers :::

	- Build Periodic 
	
		Eg.: 
			clean-up the volume on daily basis 
				schedule to run on daily basis 
				schedule using crontab

	- Poll SCM :
	
			It will trigger job based upon the schedule if there is any changes happened in src code repo.
			
			Test cycles :::
				- 8am, 12pm, 3pm
	
	- Github webhook :
			It will trigger the job as soon a commit happened in the src code repo.
			It will trigger job for every commit in repo.
			config webhook url in the repo.
			
			http://13.235.86.157:8080/github-webhook/
	
			http://3.108.59.111:8080/github-webhook/
	

	
	- Email_Notification ::


				- GMAIL LOGIN ID
				- APP TOKEN

					- login to gmail account 
					- got account settings 
					- Click Security Tab 
					- Create 2 - way Auth with active mobile number 
					- Search for App password 
					- Enter the Name for App Password and click on Create. 
					- This will Generate 16 bytes of App Password 

	- Upgrade / Backup / Recovery :::
	

*************************
Day - 5 - 14th Oct. 2023
*************************	

IAC Tools :

Fundamentals of Ansible and Terraform :::

	IAC Tools ::
	
		- Infra-Structure As Code.
		
		How the server provision is done?
		
		How the Configurations are done in the servers?
		
		Testing :::
		
		Test servers are required only during the testing phase. 
		
		Infra-Structure Team == using some shell scripts or in-house tools 
		
	IAC Tools ::
	
		Server Provisioning 		--> Terraform is used for server provisioning/Creations
		
		Configuration Management 	--> Ansible to configure the servers - Install/Manage the packages.
		
		
	Fundamentals of Ansible :::
	
		What is Ansible ?
		
			Ansible - Is a Configuration Management Tool - used to configure the servers - Install/Manage the packages.
		Purpose/Usecase of Ansible ?
		
		Ansible Architecture - and its components.
		
			Inventory Files
			
			Modules 
			
			ansible.cfg
			
		Working with Ansible ::
		
			- Ansible Adhoc Commands
			
					[dev_servers] --> git --version 
  
			- Ansible Playbooks  --> To ensure reusability.
			
					Install Maven --> 
			
					[build_servers]

							install git 
							install jdk
							install maven 
							
		Installation & Configuration of Ansible :::
		
			AWS ::
			
				Launch 3 VMs 
				
					1 - AC, 2 - Ansible Nodes
		
			
			Authentication? using ssh keys.
			
			userid
			auth ::
			
			key based auth. 
			
			
*************************
Day - 6 - 15th Oct. 2023
*************************				
			
			Ansible Modules :::
			
				The modules will be pushed into the target server 
				Execute
				Upon Execute, the module will be automatically remove from target server.
				
			Ansible Playbooks : written using *.yaml scripts.
			
			yaml --> key-value 
			
			Playbooks is used to execute the series of tasks.
			Modules
				fetch 
				copy 
				
			Reusability ::::
			
				Handling Variables in Yaml files ::::
				Roles ==> used to organise, reuse and share teh ansible components.
				
			Variables :::
			
				Using Default variables using ansible facts
				
				User Defined variables :::
			
					- Hardcoded in the playbook using vars key.
					- Using External Variable files using vars_files key.
					- Using Extra values using -e by parameterizing the playbook.
					
		
			Register 
			Handlers 
			Loops 
			Roles 
		
		
		debug :::

*************************
Day - 6 - 15th Oct. 2023
*************************				
		
		IAC Terraform :::
		
		Fundamentals of Terraform ::
		
		Provisioning / Configuration :
		
			Architecture 
			Steps involved in Terraform.
			
			
			
			Create a QA_Server - Testing :::
			
			
		
		SCM_Checkout --> Appln. Build --> Create QA_Server --> Config QA_Server -->  Deploy to QA_server --> Test the Application
		
		
		Steps Involved ::::
		
			- Identify the scope for Infra-Structure
			- Write Script 
			- terraform init 	--> Download the terraform provider
			- terraform plan 	--> Review/validate the terraform config/script file
			- terraform apply   --> Will implement the actual changes in target.
			
			
			
		Install Terraform ==> https://developer.hashicorp.com/terraform/downloads
		
		
		windows ::::
		
		download the amd64 
		extract
		Create environment variable.
		
		Install Terraform.
		Visual Studio Code - IDE 
			Install - Terraform Extension for VSCode
		
		terminals 
		
		
		Terraform is used to :::
		
			create/add			+
			destroy/delete		-
			change/update		~
			
			
*************************
Day - 7 - 21st Oct. 2023
*************************			
			
			
			Terraform State File Management :::::
			
			maintain the scripts(Resource definition - *.tf & tfstate files) in the Remote Repository. 
			
			Terraform_project Folder :
				aws.tf 					
						terraform init 
				*.exec 
						terraform plan 
						
						terraform apply 
					
				lock 
				tfstate.dummy 			==> Current state of the the target environment
				tfstate					==> Previous state of the target environment 
				
					
			SCM_Checkout --> Appln. Build --> Create QA_Server --> Config QA_Server -->  Deploy to QA_server --> Test the Application
			
			Upstream Job1 ::
			
				Create QA_Server --> Config QA_Server
			
			DownStream Job ::
			
				SCM_Checkout --> Appln. Build -->  Deploy to QA_server --> Test the Application
				
Next :	
		Docker :::
		Kubernetes :::
		Monitoring - Prometheus&Grafana :::



			
*************************
Day - 7 - 21st Oct. 2023
*************************
			
		Docker :::

			Containerization :::::
			
				Jenkins_Master :::		To create/manage Jenkins Pipeline Projects & Schedule to nodes.
					Jenkins_Slave1 :::		Java Appln. Build 
					Jenkins_Slave2 :::		Python Based web Appln. Build 
					
					Each Server is a billable 
					
			Virtual Machines ::::  Why we need VM ???
			
			-> VMs are considered as Hardware level virtualization.
			-> It is basically used to run the Operating System.
			-> VM can still up and running with simple OS, even without any Application.
			-> VM Consume more resources - CPU, Memory
			-> It consume considerable amount of time to boot-up.
			-> Hypervisors are used to create Multiple VMs. 
			
			
			
			Containerization ::::
			
			-> Containers are considered as OS Level Virtualization.
			-> Containers are basically used to run the Application. NOT Operating System.
			-> Containers Consume less resources - CPU, Memory
			-> Containers are faster in bootup & Execution
			-> The Containers will automatically go to Exit State, if the task/application completes.
			-> Containers Runs in a completly Isolated platform 
					--> Control Groups (CG) - Namespaces -- of  Kernel
			-> Container Engine is used to Create Multiple Containers
					
			
			
			Using Containers we can reduce the no. of VMs. 
			
			Containers :::
			
				- Infra-Structure Perspective :
				
					Using VMs - Jenkins Architecture :::
						
						Jenkins_Master 		==> (VM) --> Used to Create/Manage Jenkins Jobs and Schedule the jobs to slave nodes.
							Jenkins_Slave1	==> (VM) --> Used to perform the actual builds. Java 
							Jenkins_Slave2	==> (VM) --> Used to perform the actual builds. python 	
							Jenkins_Slave3	==> (VM) --> Used to perform the actual builds. Angular	
							Jenkins_Slave4	==> (VM) --> Used to perform the actual builds. NodeJS 			
						
					Using Containers - Jenkins Architecture :::
					
						Jenkins_Master 		==> (VM) --> Used to Create/Manage Jenkins Jobs and Schedule the jobs to slave nodes.
							Jenkins_Slave1	==> (VM)
								Install Container_Engine :
									Container1 ==> Java appln build 
									Container2 ==> Python appln build 								
									Container3 ==> Angular appln build 
									Container4 ==> NodeJS appln build 	
								
								
				- Development/Deployment Perspective :
				
					Developers ::
						Create the Src_Code 
						Build Application Artifacts			- mywebapp1.war,mywebapp2.war
						Unit Testing --> 
							Run the Application to do the unit testing using the local tomcat server 
												jdk1.8, tomcat 8.5 ==> mywebapp1.war
												Openjdk11, tomcat 8.7 ==> mywebapp2.war
												
								Package --> Image -->	(mywebapp1.war,	jdk1.8, tomcat 8.5)			--> mywebapp1_Img	
								Package --> Image --> 	(mywebapp2.war,	opendjdk11, tomcat 8.7)		--> mywebapp2_Img
								
							Containerization --> It is a process of packaging the Application along with its dependencies.
								
								Image.
						
						Promote the artifacts to Test Environment ???
						
							To run the application ???
							
							QA Environment 		==> mywebapp1.war				mywebapp1_pkg,mywebapp2_pkg
									openjdk11,tomcat8.0 ==> 
								
							UAT Environment 		==> mywebapp1.war
									openjdk17,tomcat10.0 ==> 				
							
				
			- Terminologies :::
			
				- Container Engine 		--> It is used to create/run/Manage the containers.
				- Image					--> A Static file, composed of various layers that defines the Application and its dependencies.
											Non-Executable.
				- Container				--> Container is the executable unit of Container Image.
				- Container Registry	--> It is used to store and Manage the Container Images. - Dockerhub
				- Container Repository	--> Subset of Container Registry 
			
			In General, 
				
				Docker Container Engine, 		# Open Source 
					- Utilizes the Control Group / Namespaces properties of Kernel to Create and manage and run the containers.
					- Docker_Hub 				# Container Registry

		
				Container Orchestration Tool ::
				
					It is used to orchestrate the Containers and ensure high availability of Containers running the applications.
					
					Docker 		==> Docker Swarm 
					
					Kubernetes 	==> Is a orchestrate the Containers and ensure high avaiability of Containers running the applications.
									
				Micro-Service :::
				
					E_Commerce :::
					
					3 - Tier ==>  Front_End, Application_logic, Back_End (DataBase)
				
				Sign_In		==> 	C1,C2,C3	==>  


				Managed Services ::	
						AWS 	- ECS, ECR, EKS 
						AZURE   - ACS, ACR, AKS
						GCP     - GCS, GCR, GKS 			
		
		
			- Create Account - Dockerhub.
			
			
			- Install Docker_Engine
				
					sudo -i
					apt install docker.io -y
					systemctl status docker
					docker --version
					
					
			
			- Docker CLI - Command		

					docker --version
					docker images
					docker ps 
					docker ps -a
			
					docker pull <image_name> 
					docker run <image_name>
					
					Mode of Container Execution :::
					
						docker run <image_name> 
					
						- Attached Mode / Foreground mode 		#Default Mode of Execution.
						
								docker run centos sleep 20
						
						- Detached Mode / Background Mode 
						
								docker run -d centos sleep 20
						
						- Interactive Mode 
						
								docker run -it centos
								
					
					docker rmi <image_Id> 				# Remove Image 
					
					docker rmi -f <image_Id> 			# Remove Image forcefully.
						(or) 
					Remove the corresponding Container & then remove that image.
					
						
					docker rm <container_id>			# Remove Container
					
					docker rm ebc58e 3dd3f58ee 12a023c
					
					docker history 5d0da3dc9764
					
					docker inspect 8bf78017009e
					
					docker logs <container_id>
					
					docker stop <container_id>
					
					docker start <container_id>
					
					
			- Port Mapping / Binding :::
				
				Tomcat - Web Application Server ::: Port 8080.
					
				docker run -it -p 8089:8080 tomcat:8.0
				
				# -p <host_port>:<container_port>
					
					
			- Docker Volumes ::::

				Container ::::
				
					- Stateless Application :
							The Applications that will never leave a trace of Execution.
					
					- Stateful Application :
							The Applications that runs inside the container and leave a trace of Execution in the form of Report/logs/outfile.
							
						Sign_In Service ::	
						
							Front_End 			- C1
					
							Application_logic 	- C2
							
							Back_End 			- C3 
					
					
					
			
			docker run -it --mount source=SA-RD_vol1,destination=/SA-RD_vol1 centos


		
			
			
			
    1  apt update -y
    2  git -version
    3  git --version
    4  apt install git -y
    5  sudo apt update -y
    6  sudo apt install openjdk-11-jre -y
    7  sudo apt update -y
    8  sudo apt install maven -y
    9  mvn --version
   10  clear
   11  useradd devopsadmin -s /bin/bash -m -d /home/devopsadmin
   12  su - devopsadmin
   13  mvn -- version
   14  mvn --version
   15  clear
   16  su - devopsadmin
   17  clear
   18  docker ps
   19  docker volume list
   20  docker volume create SA-RD_vol1
   21  docker volume inspect SA-RD_vol1
   22  cd /var/lib/docker/volumes/SA-RD_vol1
   23  ls
   24  cd _data/
   25  clear
   26  ls
   27  pwd
   28  clear
   29  cd ~
   30  docker volume list
   31  docker run -it centos
   32  docker run -it --mount source=SA-RD_vol1,destination=/SA-RD_vol1 centos
   33  cd /var/lib/docker/volumes/SA-RD_vol1/_data/
   34  ls
   35  cat container_file1
   36  clear
   37  ls
   38  echo "rec" >> filefromhost.txt
   39  ls
   40  cd ~
   41  docker run -it --mount source=SA-RD_vol1,destination=/SA-RD_vol1 centos
   42  cd /var/lib/docker/volumes/SA-RD_vol1/_data/
   43  cat filefromhost.txt
   44  cd ~
   45  clear
   46  history
		
			
*************************
Day - 8 - 22nd Oct. 2023
*************************	


		How to Build Docker Images 
		Overview of Docker Compose
		Docker Swarm 
		
		Kubenetes:	
		
			Architecture of Kubernetes & its components.
			
			
		Create Docker Images :::	
		
			Docker Commit :::
			
				docker run -it centos 
				# Install git, jdk, maven 
				# Clone 
				# exit 
			
					docker commit <contianer_id> # Create New Image.
				Eg.:
					docker commit af6ed586906d loksaieta/sa-rd-deb-git:v1.0

					
					
				docker run -it centos
			
			Docker Build ::
			
				Dockerfile ::
					Create the Definitions -->
					Layers 
					
				docker build -t  image_name .		# Create a New Image.
				
				
				docker start af6ed586906d

				docker exec -it af6ed586906d bash
				
				
				docker run -it <image_id> bash
				
				docker exec -it <Container_id> bash			# Login to a running container.
	
	
			Infra-Structure ::::
			
					1. Configure my web application Server for Testing.
					
						jdk,tomcat 
			
			
					docker run -it ubuntu
					# install jdk 
					# install tomcat 
					# Expose to 8080
					# start tomcat 
					# exit 
					
					<container_id> 
					
					docker commit <container_id> <tomcat_server_Image> 
					
			
			Development/Deployment :::
			
			
					Package the Application Artifacts :::
					
					Dockerfile :::
					
						Set of Instructions used to create the Layers of Image.
					
			root@ip-172-31-9-239:~/docker-contents# cat Dockerfile
						FROM debian
						RUN apt-get update
						RUN apt-get install git -y
						
					docker build -t loksaieta/sa-rd-debgit1:s1.0 .

			
			
				Dockerfile :
				
					FROM debian
					RUN apt-get update -y
					RUN apt-get install git -y 	


				Instructions ::
				
				FROM  	--> Used to specify the base image. 
				
				RUN 	--> Used to run the package managers to manage the package within the container.
				
				COPY	--> Used to copy the files from host machine into the container volume/Dir. 
				
				CP		--> Used to copy the files within the container volumes/dir.
				
				WORKDIR --> Used to identify the current working directory.
				
				ENV 	--> Used to Create Environment Variables
				
				EXPOSE	--> It is used to Expose the Container Port. 
				
				CMD		--> Used to specific the default/start-up command to run the container. 
							This allow users to pass any commands at runtime. 
				
				ENTRYPOINT	--> Used to specific the default/start-up command to run the container.
								This Will not allow users to pass any commands at runtime. 
						
			
			
			
			
			Publish the Images to Docker Hub Registry ::::
			
				Dockerhub Login Process :::
				
				cli/api ==> Create Access Token 
				
				docker login -u loksaieta
				
				dckr_pat_pWFNw-oDq0kbFU2BnknywRotrNU
				
				docker push <images_Name>
				
				
			Docker Compose :::
			
				Is used to run multiple containers as a service.

							
						Sign_In Service ::	
						
							Front_End 			- C1
					
							Application_logic 	- C2
							
							Back_End 			- C3 
									
			
		
				Docker Compose :::
				
					Manifest File ==> Is used to define the containers.
					
			
				Container Orchestration Tool ::
				
					It is used to orchestrate the Containers and ensure high availability of Containers running the applications.
					
					Docker 		==> Docker Swarm 
					
					Kubernetes 	==> Is a orchestrate the Containers and ensure high avaiability of Containers running the applications.

					a Container --> 
					
					
					Replicas of Containers - 3 replicas :::
					
					Kubenetes :::
					
						- Is a Open-Source Container Orchestration Tool.
						- Is a orchestrate the Containers and ensure high avaiability of Containers running the applications.
						
						- Master / Nodes Architecture.
						
						Kubernetes Architecture :
						Installation/Setup Kubenetes Master and WorkerNodes :
						

				Managed Services ::	
						AWS 	- ECS, ECR, EKS 
						AZURE   - ACS, ACR, AKS
						GCP     - GCS, GCR, GKS 							
						
		
		
				Kubernetes Terminologies ::::
				
					Images 
					Containers 
					Pods 				==> Smallest/ Atomic unit of task/schedule - Pod can have one or more containers.
											Pod IP will be assigned to a pod. 
					Deployment Controllers 
					Services
					Networking 
					Namespaces
					Cluster 			==> Collection of Worknodes.
					
					Tomcat Appln Container ==> Deployed in the form of Pods.
					Replicas of Pod - 6
		
					Kubernetes Architecture :
					Installation/Setup Kubenetes Master and WorkerNodes :
					
					
					kubeadm - utility 
					miniqube
					
						Kubenetes_Master 
							Kubenetes_WorkNode1(VM)	2 copies
							Kubenetes_WorkNode2		2 copies
							Kubenetes_WorkNode3		2 copies
		
						Kubenetes_Master 
							Cluster1 :
								Kubenetes_WorkNode1
								Kubenetes_WorkNode2
								Kubenetes_WorkNode3	
							Cluster2 :
								Kubenetes_WorkNode1
								Kubenetes_WorkNode2
								Kubenetes_WorkNode3	

					
					Hardware :: VM -- 3GB RAM / 2+ CPUs
					
						t2.micro 
					
					1. Nodes - 

						Kubenetes_Master 				There should be full access to all the nodes.
							Kubenetes_WorkNode1
							Kubenetes_WorkNode2
							
					2. Tag the Node Name.
					3. Docker 
					4. Container Runtime Interface - ContainerD
					5. ContainerD is up & running 
					6. Install kubelet, kubeadm, kubectl 
					7. Port to exposed.


				Deploy the Pods ::
				
				Kubectl 
				
				Pods 
































######################Install TOMCAT Application Server on Ubuntu :::

sudo apt update
sudo apt install openjdk-11-jre -y 
java -version

#edit /etc/profile & add JAVA_HOME

#/usr/lib/jvm/java-11-openjdk-amd64/

vi /etc/profile

/usr/lib/jvm/java-11-openjdk-amd64
/usr/lib/jvm/java-11-openjdk-amd64

export JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
PATH=$PATH:$HOME/bin:$JAVA_HOME/bin

source /etc/profile

Install Tomcat ::  https://tomcat.apache.org/download-80.cgi

https://dlcdn.apache.org/tomcat/tomcat-8/v8.5.94/bin/apache-tomcat-8.5.94.tar.gz

cd /opt
wget https://dlcdn.apache.org/tomcat/tomcat-8/v8.5.94/bin/apache-tomcat-8.5.94.tar.gz
tar -xvzf /opt/apache-tomcat-8.5.94.tar.gz

mv apache-tomcat-8.5.94 tomcat

#Start Tomcat Server:
#Goto:

cd /opt/tomcat/bin
./startup.sh

###########################################

#Add User : 

#useradd -m -d /home/devopsadmin devopsadmin
#useradd devopsadmin

useradd devopsadmin -s /bin/bash -m -d /home/devopsadmin

su - devopsadmin

#ssh-keygen

#for Ubuntu ::
ssh-keygen -t rsa -b 2048 -m PEM


ls ~/.ssh 

#You should see following two files:

#id_rsa - private key
#id_rsa.pub - public


cat id_rsa.pub > authorized_keys

chown -R devopsadmin /home/devopsadmin/.ssh
chmod 600 /home/devopsadmin/.ssh/authorized_keys
chmod 700 /home/devopsadmin/.ssh

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#make devopsadmin user as a owner to tomcat dir :

chown -R devopsadmin /opt/tomcat

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Deployment --> Copy the artifacts from source to target server 

	--> Jenkins_Slave 											--->					Tomcat_Server 
			target/mvn-hello-world.war							====>					/opt/tomcat/webapps/	
			
			
Install publish over ssh in Jenkins Master 		& restart jenkins 	








